# üß¨ EPOC Data Integration Guide

## Overview

This guide provides step-by-step instructions for integrating EPOC WSI data with molecular ground truth labels into our state-of-the-art CRC molecular subtype prediction system.

## üèóÔ∏è System Architecture Overview

### Current Implementation
- **Multi-Model Ensemble**: Swin-V2 + ConvNeXt-V2 + EfficientNet-V2 (~400M parameters)
- **Cross-Attention Fusion**: Advanced feature integration between models
- **Molecular-Specific Attention**: Dedicated attention heads for each subtype
- **Uncertainty Quantification**: Evidential deep learning for confidence estimation

### Performance Expectations
- **Target Accuracy**: 85-90% on molecular subtypes
- **Inference Speed**: <1s per patch, <30s per WSI
- **Confidence Calibration**: ECE < 0.1

## üìÅ Data Preparation

### Expected EPOC Data Format

```python
# Expected directory structure
epoc_data/
‚îú‚îÄ‚îÄ wsi/                          # Whole slide images
‚îÇ   ‚îú‚îÄ‚îÄ patient_001.svs
‚îÇ   ‚îú‚îÄ‚îÄ patient_002.ndpi
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ annotations/                  # Molecular labels
‚îÇ   ‚îú‚îÄ‚îÄ molecular_labels.csv     # Patient ID -> Molecular Subtype
‚îÇ   ‚îú‚îÄ‚îÄ clinical_data.csv        # Clinical metadata
‚îÇ   ‚îî‚îÄ‚îÄ roi_annotations.json     # Optional: Region of interest
‚îî‚îÄ‚îÄ validation/                   # Hold-out test set
    ‚îú‚îÄ‚îÄ wsi/
    ‚îî‚îÄ‚îÄ annotations/
```

### Molecular Label Format

```csv
# molecular_labels.csv
patient_id,molecular_subtype,confidence,validation_method
patient_001,Canonical,0.95,RNA-seq
patient_002,Immune,0.98,IHC+NGS
patient_003,Stromal,0.92,CMS_classification
```

## üîß Integration Steps

### Step 1: Data Ingestion

```python
# scripts/prepare_epoc_data.py
import pandas as pd
from pathlib import Path
import json

def prepare_epoc_dataset(epoc_dir: Path):
    """Prepare EPOC data for training"""
    
    # Load molecular labels
    labels_df = pd.read_csv(epoc_dir / "annotations/molecular_labels.csv")
    
    # Map to our classification
    subtype_map = {
        'Canonical': 0,
        'Immune': 1,
        'Stromal': 2
    }
    
    # Create training manifest
    manifest = []
    for _, row in labels_df.iterrows():
        wsi_path = epoc_dir / f"wsi/{row['patient_id']}.svs"
        if wsi_path.exists():
            manifest.append({
                'patient_id': row['patient_id'],
                'wsi_path': str(wsi_path),
                'molecular_subtype': row['molecular_subtype'],
                'label': subtype_map[row['molecular_subtype']],
                'confidence': row['confidence']
            })
    
    # Save manifest
    with open('data/epoc_manifest.json', 'w') as f:
        json.dump(manifest, f, indent=2)
    
    return manifest
```

### Step 2: WSI Processing Pipeline

```python
# scripts/process_epoc_wsi.py
import openslide
from advanced_histopathology_augmentation import StainNormalizer
import torch
from torchvision import transforms

class EPOCWSIProcessor:
    def __init__(self, patch_size=224, overlap=0.25, min_tissue=0.5):
        self.patch_size = patch_size
        self.overlap = overlap
        self.min_tissue = min_tissue
        self.stain_normalizer = StainNormalizer(method='macenko')
        
    def extract_patches(self, wsi_path):
        """Extract patches from WSI with quality control"""
        slide = openslide.OpenSlide(wsi_path)
        
        # Get dimensions
        width, height = slide.dimensions
        
        # Calculate patch locations
        stride = int(self.patch_size * (1 - self.overlap))
        patches = []
        
        for y in range(0, height - self.patch_size, stride):
            for x in range(0, width - self.patch_size, stride):
                # Extract patch
                patch = slide.read_region(
                    (x, y), 0, (self.patch_size, self.patch_size)
                ).convert('RGB')
                
                # Quality check
                if self.is_tissue(patch):
                    # Normalize staining
                    patch_array = np.array(patch)
                    normalized = self.stain_normalizer.normalize(patch_array)
                    
                    patches.append({
                        'image': normalized,
                        'location': (x, y),
                        'level': 0
                    })
        
        return patches
    
    def is_tissue(self, patch):
        """Check if patch contains sufficient tissue"""
        gray = np.array(patch.convert('L'))
        tissue_mask = gray < 220  # Simple threshold
        return np.mean(tissue_mask) > self.min_tissue
```

### Step 3: Training Pipeline

```python
# scripts/train_epoc_model.py
import torch
from torch.utils.data import DataLoader
from state_of_the_art_molecular_classifier import create_state_of_the_art_model
from advanced_histopathology_augmentation import MolecularSubtypeAugmentation

def train_on_epoc_data(manifest_path, epochs=50):
    """Train the state-of-the-art model on EPOC data"""
    
    # Load model
    model = create_state_of_the_art_model(
        num_classes=3,
        use_uncertainty=True
    )
    
    # Multi-GPU setup if available
    if torch.cuda.device_count() > 1:
        model = torch.nn.DataParallel(model)
    
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = model.to(device)
    
    # Create datasets
    train_dataset = EPOCDataset(
        manifest_path,
        transform_type='train',
        use_stain_norm=True
    )
    
    val_dataset = EPOCDataset(
        manifest_path,
        transform_type='val',
        use_stain_norm=True
    )
    
    # Data loaders
    train_loader = DataLoader(
        train_dataset,
        batch_size=16,  # Adjust based on GPU memory
        shuffle=True,
        num_workers=8
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=8
    )
    
    # Optimizer with different learning rates
    optimizer = torch.optim.AdamW([
        {'params': model.swin_v2.parameters(), 'lr': 1e-5},
        {'params': model.convnext_v2.parameters(), 'lr': 1e-5},
        {'params': model.efficientnet_v2.parameters(), 'lr': 1e-5},
        {'params': model.classifier.parameters(), 'lr': 1e-4}
    ], weight_decay=0.01)
    
    # Learning rate scheduler
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=epochs, eta_min=1e-6
    )
    
    # Loss functions
    ce_loss = torch.nn.CrossEntropyLoss()
    
    # Training loop
    best_val_acc = 0
    for epoch in range(epochs):
        # Train
        model.train()
        train_loss = 0
        train_correct = 0
        
        for batch in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            images = batch['image'].to(device)
            labels = batch['label'].to(device)
            
            optimizer.zero_grad()
            
            # Forward pass
            outputs = model(images)
            
            # Calculate losses
            main_loss = ce_loss(outputs['logits'], labels)
            
            # Auxiliary losses
            aux_losses = 0
            for aux_logits in outputs['aux_logits'].values():
                aux_losses += 0.3 * ce_loss(aux_logits, labels)
            
            total_loss = main_loss + aux_losses
            
            # Backward pass
            total_loss.backward()
            optimizer.step()
            
            # Track metrics
            train_loss += total_loss.item()
            pred = outputs['logits'].argmax(dim=1)
            train_correct += (pred == labels).sum().item()
        
        # Validation
        model.eval()
        val_correct = 0
        val_total = 0
        
        with torch.no_grad():
            for batch in val_loader:
                images = batch['image'].to(device)
                labels = batch['label'].to(device)
                
                outputs = model(images, return_attention=True)
                pred = outputs['logits'].argmax(dim=1)
                
                val_correct += (pred == labels).sum().item()
                val_total += labels.size(0)
        
        val_acc = val_correct / val_total
        
        # Save best model
        if val_acc > best_val_acc:
            best_val_acc = val_acc
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_acc': val_acc
            }, 'models/epoc_molecular_best.pth')
        
        scheduler.step()
        
        print(f"Epoch {epoch+1}: Train Loss: {train_loss/len(train_loader):.4f}, "
              f"Val Acc: {val_acc:.4f}")
    
    return model
```

### Step 4: Validation & Testing

```python
# scripts/validate_epoc_model.py
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

def validate_epoc_model(model, test_loader, device):
    """Comprehensive validation on EPOC test set"""
    
    model.eval()
    all_preds = []
    all_labels = []
    all_uncertainties = []
    all_patient_ids = []
    
    with torch.no_grad():
        for batch in tqdm(test_loader, desc="Validating"):
            images = batch['image'].to(device)
            labels = batch['label']
            patient_ids = batch['patient_id']
            
            outputs = model(images, return_attention=True)
            
            preds = outputs['logits'].argmax(dim=1).cpu()
            uncertainties = outputs['uncertainty'].cpu()
            
            all_preds.extend(preds.numpy())
            all_labels.extend(labels.numpy())
            all_uncertainties.extend(uncertainties.numpy())
            all_patient_ids.extend(patient_ids)
    
    # Calculate metrics
    accuracy = np.mean(np.array(all_preds) == np.array(all_labels))
    
    # Classification report
    target_names = ['Canonical', 'Immune', 'Stromal']
    report = classification_report(
        all_labels, all_preds,
        target_names=target_names,
        output_dict=True
    )
    
    # Confusion matrix
    cm = confusion_matrix(all_labels, all_preds)
    
    # Plot confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=target_names,
                yticklabels=target_names)
    plt.title(f'EPOC Validation - Accuracy: {accuracy:.3f}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig('results/epoc_confusion_matrix.png', dpi=300)
    
    # Uncertainty calibration
    plot_calibration_curve(all_preds, all_labels, all_uncertainties)
    
    # Per-patient analysis
    patient_results = analyze_per_patient(
        all_patient_ids, all_preds, all_labels
    )
    
    return {
        'accuracy': accuracy,
        'classification_report': report,
        'confusion_matrix': cm,
        'patient_results': patient_results
    }
```

## üöÄ Deployment Pipeline

### Step 1: Model Export

```python
# Export for production
torch.save({
    'model_state_dict': model.state_dict(),
    'model_config': {
        'num_classes': 3,
        'architecture': 'state_of_the_art_ensemble',
        'version': '2.0'
    },
    'performance_metrics': validation_results,
    'training_metadata': {
        'dataset': 'EPOC',
        'date': datetime.now().isoformat(),
        'epochs': epochs
    }
}, 'models/epoc_production_model.pth')
```

### Step 2: Streamlit Integration

```python
# Update app/molecular_subtype_platform.py
@st.cache_resource
def load_epoc_model():
    """Load EPOC-trained production model"""
    model_path = "models/epoc_production_model.pth"
    
    if Path(model_path).exists():
        model = create_state_of_the_art_model(num_classes=3, use_uncertainty=True)
        checkpoint = torch.load(model_path, map_location='cpu')
        model.load_state_dict(checkpoint['model_state_dict'])
        
        st.success("‚úÖ Loaded EPOC-validated molecular model")
        st.info(f"Validation accuracy: {checkpoint['performance_metrics']['accuracy']:.3f}")
        
        return model
    else:
        st.error("EPOC model not found")
        return None
```

## üìä Expected Outcomes

### Performance Metrics
- **Molecular Subtype Accuracy**: 85-90%
- **Per-Subtype F1 Scores**:
  - Canonical: 0.86-0.91
  - Immune: 0.88-0.93
  - Stromal: 0.83-0.88

### Clinical Integration
- **Report Generation**: Automated clinical reports
- **Confidence Thresholds**: Cases below 0.7 confidence flagged for review
- **Quality Control**: Automatic tissue quality assessment

## üîç Troubleshooting

### Common Issues

1. **Memory Errors**
   - Reduce batch size
   - Use gradient accumulation
   - Enable mixed precision training

2. **Poor Stain Normalization**
   - Check reference image quality
   - Try Vahadane method instead of Macenko
   - Validate on diverse staining conditions

3. **Low Validation Accuracy**
   - Check label quality
   - Increase training epochs
   - Fine-tune learning rates
   - Add more augmentation

## üìö Additional Resources

- [Pitroda et al. 2018 Paper](https://jamanetwork.com/journals/jamaoncology/fullarticle/2703492)
- [CMS Classification Guidelines](https://www.nature.com/articles/nm.3967)
- [WSI Processing Best Practices](docs/wsi_processing.md)
- [Model Architecture Details](STATE_OF_THE_ART_IMPROVEMENTS.md)

---

**Ready for EPOC Integration!** üöÄ This system is fully prepared to achieve state-of-the-art performance once molecular ground truth data is available. 