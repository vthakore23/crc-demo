# CRC Molecular Subtype Classification - Cluster Implementation Roadmap

## üéØ Executive Summary

This roadmap provides a comprehensive guide for transitioning the CRC molecular subtype classification system from development to production-ready cluster deployment with EPOC WSI data. The architecture supports distributed training across multiple GPUs/nodes, clinical-grade validation, and real-time inference.

## üìä Current State vs. Target State

### Current State
- Single-GPU training with synthetic data
- 100% accuracy on limited dataset (likely overfitting)
- Basic EfficientNet-B1 model (6.9M parameters)
- Local Streamlit deployment

### Target State
- Multi-node distributed training (32 GPUs)
- 90%+ accuracy on EPOC validation cohort
- Multi-scale hierarchical model (100M+ parameters)
- Clinical-grade deployment with uncertainty quantification

## üèóÔ∏è Architecture Components

### 1. **Data Pipeline** (`cluster/data/`)
- **WSI Processing Pipeline**: Multi-scale patch extraction with quality control
- **Distributed Processing**: Parallel processing of thousands of WSIs
- **Clinical Integration**: Metadata tracking and patient stratification

### 2. **Model Architecture** (`cluster/models/`)
- **Multi-Scale Encoder**: Hierarchical feature extraction at 20x, 10x, 5x
- **Attention Aggregation**: Local and global attention mechanisms
- **Pathway Heads**: Specialized predictors for Canonical/Immune/Stromal
- **Uncertainty Estimation**: Evidential deep learning for confidence

### 3. **Distributed Training** (`cluster/`)
- **DDP Implementation**: PyTorch DistributedDataParallel
- **Mixed Precision**: Automatic mixed precision for 2x speedup
- **Gradient Accumulation**: Effective batch size of 1024
- **Fault Tolerance**: Automatic checkpoint recovery

### 4. **Clinical Validation** (`cluster/validation/`)
- **Cross-Validation**: 5-fold stratified by institution/subtype
- **Survival Analysis**: C-index for prognostic validation
- **Calibration**: Temperature scaling for reliable probabilities
- **Subgroup Analysis**: Performance across MSI/BRAF/age groups

## üìã Implementation Phases

### Phase 1: Infrastructure Setup (Week 1-2)
```bash
# 1. Set up cluster environment
module load cuda/11.8 python/3.11
python -m venv crc_molecular_env
source crc_molecular_env/bin/activate
pip install -r requirements_cluster.txt

# 2. Configure distributed storage
mkdir -p /data/epoc/{raw,processed}
mkdir -p /scratch/{checkpoints,cache,tensorboard}/crc_molecular

# 3. Test distributed training setup
python cluster/test_distributed_setup.py --gpus 8
```

### Phase 2: Data Preprocessing (Week 2-3)
```bash
# 1. Process EPOC WSI data
sbatch cluster/preprocess_wsi.sh \
    --input /data/epoc/raw \
    --output /data/epoc/processed \
    --workers 32

# 2. Create training manifests
python cluster/data/create_manifests.py \
    --processed_dir /data/epoc/processed \
    --stratify_by molecular_subtype,institution \
    --split_ratios 0.7,0.15,0.15

# 3. Validate data quality
python cluster/data/validate_patches.py \
    --manifest /data/epoc/processed/train_manifest.json \
    --num_samples 1000
```

### Phase 3: Model Development (Week 3-5)
```bash
# 1. Pre-train on public datasets (optional)
sbatch cluster/pretrain_foundation.sh \
    --dataset TCGA-CRC \
    --epochs 50

# 2. Launch distributed training
sbatch cluster/submit_training.sh \
    --config cluster/configs/cluster_training_config.yaml

# 3. Monitor training progress
wandb agent medical_ai_team/crc_molecular_production/sweep_id
tensorboard --logdir /scratch/tensorboard/crc_molecular
```

### Phase 4: Clinical Validation (Week 5-6)
```bash
# 1. Run cross-validation
sbatch cluster/cross_validation.sh \
    --folds 5 \
    --stratify molecular_subtype,institution

# 2. Generate clinical metrics
python cluster/clinical_metrics.py \
    --checkpoint /scratch/checkpoints/best_model.pth \
    --test_manifest /data/epoc/processed/test_manifest.json \
    --output results/clinical_metrics.json

# 3. Create validation report
python cluster/generate_clinical_report.py \
    --metrics results/clinical_metrics.json \
    --output reports/clinical_validation.pdf
```

### Phase 5: Production Deployment (Week 7-8)
```bash
# 1. Export production model
python cluster/export_production_model.py \
    --checkpoint /scratch/checkpoints/best_model.pth \
    --output models/crc_molecular_v2.0.pth \
    --optimize true

# 2. Deploy inference service
docker build -t crc-molecular:v2.0 -f Dockerfile.production .
kubectl apply -f k8s/inference-service.yaml

# 3. Validate deployment
python cluster/test_production_inference.py \
    --endpoint https://api.medical-ai.org/crc-molecular \
    --test_cases 100
```

## üîß Key Configuration Files

### 1. **Cluster Training Config**
```yaml
# cluster/configs/cluster_training_config.yaml
model:
  backbone: efficientnet_b3
  feature_dim: 512
  num_heads: 8
  depth: 4

training:
  batch_size: 32  # per GPU
  accumulation_steps: 4
  epochs: 100
  backbone_lr: 1e-5
  head_lr: 1e-3

distributed:
  nodes: 4
  gpus_per_node: 8
  backend: nccl
```

### 2. **SLURM Job Script**
```bash
#!/bin/bash
#SBATCH --nodes=4
#SBATCH --gres=gpu:8
#SBATCH --time=48:00:00
#SBATCH --mem=512GB

srun python cluster/distributed_trainer.py \
    --config cluster/configs/cluster_training_config.yaml
```

## üìà Performance Targets

| Metric | Current | Target | Method |
|--------|---------|--------|--------|
| Accuracy | 100% (overfit) | 90%+ | Proper validation |
| F1 Score (per class) | - | 0.85+ | Balanced training |
| Processing Time | - | <5 min/WSI | Optimized inference |
| Model Size | 6.9M | 100M+ | Multi-scale architecture |
| Uncertainty Calibration | - | ECE < 0.1 | Temperature scaling |

## üö® Critical Success Factors

### 1. **Data Quality**
- [ ] Pathologist-validated annotations for all EPOC cases
- [ ] Consistent staining across institutions
- [ ] Balanced representation of molecular subtypes
- [ ] Complete clinical metadata (MSI, BRAF, survival)

### 2. **Computational Resources**
- [ ] Access to 32+ V100/A100 GPUs
- [ ] High-speed distributed storage (>10GB/s)
- [ ] Reliable cluster scheduling (SLURM/Kubernetes)
- [ ] Sufficient memory for large batch processing

### 3. **Clinical Integration**
- [ ] DICOM compatibility
- [ ] HL7 FHIR integration
- [ ] Report generation system
- [ ] Audit trail compliance

### 4. **Validation Requirements**
- [ ] Multi-institutional validation
- [ ] Prospective clinical trial design
- [ ] Regulatory approval pathway
- [ ] Inter-observer agreement studies

## üîç Monitoring & Debugging

### Training Monitoring
```python
# Real-time metrics tracking
wandb.log({
    'train/loss': loss.item(),
    'train/accuracy': accuracy,
    'val/f1_canonical': f1_scores[0],
    'val/f1_immune': f1_scores[1],
    'val/f1_stromal': f1_scores[2],
    'learning_rate': optimizer.param_groups[0]['lr'],
    'gpu_memory': torch.cuda.max_memory_allocated()
})
```

### Production Monitoring
```python
# Performance tracking
monitor.log_prediction(
    patient_id=patient_id,
    prediction=prediction,
    confidence=confidence,
    processing_time=elapsed_time,
    patch_count=num_patches
)
```

## üìö Additional Resources

### Documentation
- [WSI Processing Guide](docs/wsi_processing.md)
- [Model Architecture Details](docs/model_architecture.md)
- [Clinical Validation Protocol](docs/clinical_validation.md)
- [API Reference](docs/api_reference.md)

### Scripts & Tools
- `cluster/tools/visualize_predictions.py` - Generate heatmaps
- `cluster/tools/analyze_errors.py` - Error analysis
- `cluster/tools/benchmark_inference.py` - Performance testing
- `cluster/tools/data_quality_report.py` - Data validation

## üéØ Next Steps

1. **Immediate Actions**
   - [ ] Request cluster access and GPU allocation
   - [ ] Set up data transfer for EPOC WSIs
   - [ ] Initialize experiment tracking (W&B)
   - [ ] Create backup and recovery procedures

2. **Week 1 Goals**
   - [ ] Complete infrastructure setup
   - [ ] Process first 100 EPOC cases
   - [ ] Validate distributed training pipeline
   - [ ] Establish baseline metrics

3. **Month 1 Deliverables**
   - [ ] Fully processed EPOC dataset
   - [ ] Trained multi-scale model
   - [ ] Clinical validation report
   - [ ] Production deployment plan

## ü§ù Team Responsibilities

| Role | Responsibilities | Contact |
|------|-----------------|---------|
| ML Engineer | Model development, distributed training | ml-team@ |
| Data Engineer | WSI processing, pipeline optimization | data-team@ |
| Clinical Lead | Annotation validation, clinical metrics | clinical@ |
| DevOps | Cluster management, deployment | devops@ |
| Project Manager | Timeline, resources, stakeholder comm | pm@ |

---

**Note**: This implementation represents a significant scale-up from the current prototype. Success depends on close collaboration between technical and clinical teams, adequate computational resources, and rigorous validation protocols. Regular checkpoints and iterative improvements will be essential for achieving clinical-grade performance. 